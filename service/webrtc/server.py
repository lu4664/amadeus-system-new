# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import fastapi  # ç”¨äºåˆ›å»ºWeb APIæœåŠ¡
from fastapi.responses import FileResponse  # ç”¨äºè¿”å›æ–‡ä»¶å“åº”
from fastrtc import ReplyOnPause, Stream, AdditionalOutputs, audio_to_bytes  # ç”¨äºå¤„ç†WebRTCæµ
import logging  # ç”¨äºè®°å½•æ—¥å¿—
import time  # ç”¨äºè®¡æ—¶å’Œæ—¶é—´ç›¸å…³æ“ä½œ
import gradio as gr
# è®¾ç½®æ—¥å¿—çº§åˆ«ï¼Œè®© aiortc/aioice åå‡ºè¿æ¥ç»†èŠ‚
logging.basicConfig(level=logging.INFO)
logging.getLogger("aioice").setLevel(logging.DEBUG)
from fastapi.middleware.cors import CORSMiddleware  # ç”¨äºå¤„ç†è·¨åŸŸè¯·æ±‚
import numpy as np  # ç”¨äºæ•°å€¼è®¡ç®—å’Œæ•°ç»„æ“ä½œ
import io  # ç”¨äºå¤„ç†è¾“å…¥è¾“å‡ºæµ
import requests  # ç”¨äºå‘é€HTTPè¯·æ±‚
import asyncio  # ç”¨äºå¼‚æ­¥ç¼–ç¨‹
from mem0 import AsyncMemoryClient
import os  # ç”¨äºæ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½
from io import BytesIO  # ç”¨äºåœ¨å†…å­˜ä¸­å¤„ç†äºŒè¿›åˆ¶æ•°æ®
from dotenv import load_dotenv  # ç”¨äºåŠ è½½ç¯å¢ƒå˜é‡
import aiohttp  # ç”¨äºå¼‚æ­¥HTTPè¯·æ±‚
import json  # ç”¨äºJSONå¤„ç†
from datetime import datetime, timedelta
from typing import Dict, Optional
from openai import OpenAI
# å¯¼å…¥è‡ªå®šä¹‰çš„å·¥å…·å‡½æ•°
from utils import run_async, generate_sys_prompt, process_llm_stream, generate_unique_user_id
from ai import ai_stream, AI_MODEL, predict_emotion  # ä»aiæ¨¡å—å¯¼å…¥
from ai.plan import ActionPlanner  # å¯¼å…¥ActionPlannerç±»
from stt import transcribe
from tts import text_to_speech_stream
from routes import router, init_router, get_user_config, InputData  # å¯¼å…¥è·¯ç”±æ¨¡å—åŠç”¨æˆ·é…ç½®
from contextlib import asynccontextmanager

# åŠ è½½é»˜è®¤ç¯å¢ƒå˜é‡ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
load_dotenv()

from humaware_vad import HumAwareVADModel
vad_model = HumAwareVADModel()

# è·å–é»˜è®¤ç¯å¢ƒå˜é‡
DEFAULT_LLM_API_KEY = os.getenv("LLM_API_KEY", "")
DEFAULT_WHISPER_API_KEY = os.getenv("WHISPER_API_KEY", "")
DEFAULT_SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY", "")
DEFAULT_LLM_BASE_URL = os.getenv("LLM_BASE_URL", "https://api.ephone.ai/v1")
DEFAULT_WHISPER_BASE_URL = os.getenv("WHISPER_BASE_URL", "https://amadeus-ai-api-2.zeabur.app/v1")
DEFAULT_AI_MODEL = os.getenv("AI_MODEL")
DEFAULT_WHISPER_MODEL = os.getenv("WHISPER_MODEL", "whisper-large-v3")
DEFAULT_MEM0_API_KEY = os.getenv("MEM0_API_KEY", "")
# æ·»åŠ WebRTCæµçš„æ—¶é—´é™åˆ¶å’Œå¹¶å‘é™åˆ¶ç¯å¢ƒå˜é‡
DEFAULT_TIME_LIMIT = int(os.getenv("TIME_LIMIT", "600"))
DEFAULT_CONCURRENCY_LIMIT = int(os.getenv("CONCURRENCY_LIMIT", "10"))

# è®¾ç½®é»˜è®¤çš„è¯­è¨€é€‰é¡¹å’Œå‚æ•°
DEFAULT_VOICE_OUTPUT_LANGUAGE = 'ja'
DEFAULT_TEXT_OUTPUT_LANGUAGE = 'zh'
DEFAULT_SYSTEM_PROMPT = """å‘½è¿çŸ³ä¹‹é—¨(steins gate)çš„ç‰§æ¿‘çº¢è‰æ –(kurisu),ä¸€ä¸ªå¤©æ‰å°‘å¥³,æ€§æ ¼å‚²å¨‡,ä¸å–œæ¬¢è¢«å«å…‹é‡Œæ–¯è’‚å¨œ"""
DEFAULT_USER_NAME = "ç”¨æˆ·"
# ä¼šè¯è¶…æ—¶è®¾ç½®
SESSION_TIMEOUT = timedelta(seconds=DEFAULT_TIME_LIMIT)
# æ¸…ç†é—´éš”
CLEANUP_INTERVAL = 60

# ç”¨æˆ·ä¼šè¯çŠ¶æ€å­—å…¸ï¼Œå­˜å‚¨æ¯ä¸ªç”¨æˆ·çš„æ¶ˆæ¯ã€è®¾ç½®ç­‰
user_sessions = {}
# ç”¨æˆ·ä¼šè¯æœ€åæ´»åŠ¨æ—¶é—´
user_sessions_last_active = {}

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯å­—å…¸ï¼Œä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºä¸€ä¸ªå®¢æˆ·ç«¯
openai_clients = {}

# å¼‚æ­¥æ¸…ç†è¿‡æœŸä¼šè¯
async def cleanup_expired_sessions():
    while True:
        try:
            await asyncio.sleep(CLEANUP_INTERVAL)
            current_time = time.time()
            expired_sessions = []
            
            # æŸ¥æ‰¾è¿‡æœŸä¼šè¯
            for webrtc_id, last_active in user_sessions_last_active.items():
                if current_time - last_active > SESSION_TIMEOUT.total_seconds():
                    expired_sessions.append(webrtc_id)
            
            # æ¸…ç†è¿‡æœŸä¼šè¯
            for webrtc_id in expired_sessions:
                logging.info(f"æ¸…ç†è¿‡æœŸä¼šè¯: {webrtc_id}")
                user_sessions.pop(webrtc_id, None)
                user_sessions_last_active.pop(webrtc_id, None)
                openai_clients.pop(webrtc_id, None)
                
            logging.info(f"æ¸…ç†å®Œæˆï¼Œå½“å‰æ´»è·ƒä¼šè¯æ•°: {len(user_sessions)}")
        except Exception as e:
            logging.error(f"æ¸…ç†è¿‡æœŸä¼šè¯æ—¶å‡ºé”™: {e}")

# è·å–ç”¨æˆ·ç‰¹å®šçš„ä¼šè¯çŠ¶æ€
def get_user_session(webrtc_id: str):
    # æ›´æ–°ç”¨æˆ·æœ€åæ´»åŠ¨æ—¶é—´
    user_sessions_last_active[webrtc_id] = time.time()
    
    if webrtc_id not in user_sessions:
        # åˆ›å»ºæ–°ç”¨æˆ·çš„åˆå§‹ä¼šè¯çŠ¶æ€
        config = get_user_config(webrtc_id)
        voice_output_language = config.voice_output_language if config and config.voice_output_language else DEFAULT_VOICE_OUTPUT_LANGUAGE
        text_output_language = config.text_output_language if config and config.text_output_language else DEFAULT_TEXT_OUTPUT_LANGUAGE
        system_prompt = config.system_prompt if config and config.system_prompt else DEFAULT_SYSTEM_PROMPT
        user_name = config.user_name if config and config.user_name else DEFAULT_USER_NAME
        
        # ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
        sys_prompt = generate_sys_prompt(
            voice_output_language=voice_output_language,
            text_output_language=text_output_language,
            is_same_language=(voice_output_language == text_output_language),
            current_user_name=user_name,
            system_prompt=system_prompt,
            model=get_user_ai_model(webrtc_id)
        )
        
        # åˆ›å»ºåˆå§‹æ¶ˆæ¯åˆ—è¡¨
        user_sessions[webrtc_id] = {
            "messages": [{"role": "system", "content": sys_prompt}],
            "voice_output_language": voice_output_language,
            "text_output_language": text_output_language,
            "system_prompt": system_prompt,
            "user_name": user_name,
            "is_same_language": (voice_output_language == text_output_language),
            "next_action": None  # æ·»åŠ next_actionå­—æ®µï¼Œç”¨äºå­˜å‚¨ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’
        }
    
    return user_sessions[webrtc_id]

# è·å–ç”¨æˆ·çš„OpenAIå®¢æˆ·ç«¯
def get_user_openai_client(webrtc_id: str):
    # æ›´æ–°ç”¨æˆ·æœ€åæ´»åŠ¨æ—¶é—´
    user_sessions_last_active[webrtc_id] = time.time()
    
    if webrtc_id not in openai_clients:
        config = get_user_config(webrtc_id)
        api_key = config.llm_api_key if config and config.llm_api_key else DEFAULT_LLM_API_KEY
        base_url = config.llm_base_url if config and config.llm_base_url else DEFAULT_LLM_BASE_URL   
        openai_clients[webrtc_id] = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
    return openai_clients[webrtc_id]

# è·å–ç”¨æˆ·çš„AIæ¨¡å‹
def get_user_ai_model(webrtc_id: str):
    config = get_user_config(webrtc_id)
    return config.ai_model if config and config.ai_model else DEFAULT_AI_MODEL

# è·å–ç”¨æˆ·çš„è¯­éŸ³è½¬æ–‡æœ¬APIé…ç½®
def get_user_whisper_config(webrtc_id: str):
    config = get_user_config(webrtc_id)
    return {
        "api_key": config.whisper_api_key if config and config.whisper_api_key else DEFAULT_WHISPER_API_KEY,
        "base_url": config.whisper_base_url if config and config.whisper_base_url else DEFAULT_WHISPER_BASE_URL,
        "model": config.whisper_model if config and config.whisper_model else DEFAULT_WHISPER_MODEL
    }

# è·å–ç”¨æˆ·çš„æ–‡æœ¬è½¬è¯­éŸ³é…ç½®
def get_user_siliconflow_config(webrtc_id: str):
    config = get_user_config(webrtc_id)
    return {
        "api_key": config.siliconflow_api_key if config and config.siliconflow_api_key else DEFAULT_SILICONFLOW_API_KEY,
        "voice": config.siliconflow_voice if config and config.siliconflow_voice else None
    }

# è·å–ç”¨æˆ·çš„MEM0è®°å¿†æœåŠ¡é…ç½®
def get_user_mem0_config(webrtc_id: str):
    config = get_user_config(webrtc_id)
    return {
        "api_key": config.mem0_api_key if config and config.mem0_api_key else DEFAULT_MEM0_API_KEY
    }

logging.basicConfig(level=logging.INFO)

# âœ… ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å– TURN é…ç½®
TURN_URL = os.getenv("TURN_URL", "")
TURN_USERNAME = os.getenv("TURN_USERNAME", "")
TURN_CREDENTIAL = os.getenv("TURN_CREDENTIAL", "")

# ç¬¬182-193è¡Œæ›¿æ¢ä¸ºï¼š
ice_servers = [
    # å…¬å…± STUN æœåŠ¡å™¨ï¼ˆç”¨äº NAT ç©¿é€ï¼‰ - å¯¹å¤§å¤šæ•°ç½‘ç»œç¯å¢ƒå·²è¶³å¤Ÿ
    {
        "urls": [
            "stun:stun.l.google.com:19302",
            "stun:stun1.l.google.com:19302",
            "stun:stun2.l.google.com:19302",
            "stun:stun3.l.google.com:19302"
        ]
    },
    # å¦‚æœä»¥åéœ€è¦TURNï¼Œå¯ä»¥ä½¿ç”¨å…¶ä»–å…è´¹TURNæœåŠ¡
    # æš‚æ—¶æ³¨é‡Šæ‰æœ‰é—®é¢˜çš„Metered TURNæœåŠ¡å™¨
    # {
    #     "urls": [
    #         "turns:a.relay.metered.ca:443?transport=tcp",
    #         "turn:a.relay.metered.ca:80?transport=tcp",
    #         "turn:a.relay.metered.ca:3478"
    #     ],
    #     "username": os.getenv("TURN_USERNAME", ""),
    #     "credential": os.getenv("TURN_CREDENTIAL", "")
    # }
]

logging.info(f"ğŸ”’ ä½¿ç”¨çº¯ TURN over TCP æ¨¡å¼ï¼ˆæœ€ç¨³å®šï¼‰")

logging.info(f"ğŸŒ ä½¿ç”¨å›½å†…ä¼˜åŒ–çš„ STUN é…ç½®")

WEBRTC_API_URL = os.getenv("WEBRTC_API_URL", "http://localhost:8080")
# å…ˆå®šä¹‰ rtc_configuration
rtc_configuration = {
    "iceServers": ice_servers
}

# ç„¶åå†è¾“å‡ºè°ƒè¯•ä¿¡æ¯
logging.info(f"ğŸ” TURNé…ç½®è°ƒè¯•:")
logging.info(f"  TURN_URL: {TURN_URL}")
logging.info(f"  TURN_USERNAME: {TURN_USERNAME}")
logging.info(f"  TURN_CREDENTIAL: {'***' if TURN_CREDENTIAL else '(ç©º)'}")
logging.info(f"  æœ€ç»ˆICEé…ç½®: {json.dumps(rtc_configuration, indent=2)}")




def start_up(webrtc_id):
    logging.info(f"ç”¨æˆ· {webrtc_id} å¼€å§‹å‡½æ•°å·²æ‰§è¡Œ")
    
    # è·å–ç”¨æˆ·ä¼šè¯çŠ¶æ€
    session = get_user_session(webrtc_id)
    logging.info(f"session: {session}")
    # ç”Ÿæˆæœ€æ–°çš„ç³»ç»Ÿæç¤ºè¯  
    current_sys_prompt = generate_sys_prompt(
        voice_output_language=session["voice_output_language"],
        text_output_language=session["text_output_language"],
        is_same_language=session["is_same_language"],
        current_user_name=session["user_name"],
        system_prompt=session["system_prompt"],
        model=get_user_ai_model(webrtc_id)
    )
    
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç³»ç»Ÿæç¤ºå’Œä¸€ä¸ªç‰¹å®šçš„ç”¨æˆ·æ¶ˆæ¯
    temp_messages = [
        {"role": "system", "content": current_sys_prompt},
        {"role": "user", "content": "self_motivated"}
    ]

    logging.info(f"current_sys_prompt: {current_sys_prompt}")
    
    # è·å–ç”¨æˆ·ç›¸å…³é…ç½®
    client = get_user_openai_client(webrtc_id)
    model = get_user_ai_model(webrtc_id)
    siliconflow_config = get_user_siliconflow_config(webrtc_id)
    
    # ç”Ÿæˆç”¨æˆ·å”¯ä¸€ID
    user_id = generate_unique_user_id(session["user_name"])
    
    # ä½¿ç”¨å°è£…çš„æµå¤„ç†å‡½æ•°
    welcome_text = ""
    stream_generator = process_llm_stream(
        client=client,
        messages=temp_messages,
        model=model,
        siliconflow_config=siliconflow_config,
        voice_output_language=session["voice_output_language"],
        text_output_language=session["text_output_language"],
        is_same_language=session["is_same_language"],
        run_predict_emotion=run_predict_emotion,
        ai_stream=ai_stream,
        text_to_speech_stream=text_to_speech_stream,
        max_tokens=100,
        max_context_length=20,
    )
    
    # å¤„ç†ç”Ÿæˆå™¨çš„è¾“å‡º
    for item in stream_generator:
        if isinstance(item, str):
            welcome_text = item
        else:
            yield item
    try:
        # åˆ›å»ºActionPlannerå®ä¾‹
        action_planner = ActionPlanner(conversation_history=session["messages"][-2:])
        # å¼‚æ­¥æ‰§è¡Œè¡ŒåŠ¨è®¡åˆ’
        next_action = run_async(action_planner.plan_next_action, client)
        # æ›´æ–°ç”¨æˆ·ä¼šè¯ä¸­çš„next_actionå­—æ®µ
        session["next_action"] = next_action
        logging.info(f"åˆå§‹ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’: {next_action}")
        
        # é€šçŸ¥å‰ç«¯ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’
        next_action_json = json.dumps({"type": "next_action", "data": next_action})
        yield AdditionalOutputs(next_action_json)
    except Exception as e:
        logging.error(f"è§„åˆ’åˆå§‹ä¸‹ä¸€æ­¥è¡ŒåŠ¨å¤±è´¥: {str(e)}")
        session["next_action"] = "share_memory"  # å¤±è´¥æ—¶é»˜è®¤ä¸ºåˆ†äº«è®°å¿†

# å®šä¹‰ä¸€ä¸ªå¼‚æ­¥å‡½æ•°æ¥è¿è¡Œpredict_emotion
async def run_predict_emotion(message, client=None):
    """
    å¼‚æ­¥è¿è¡Œpredict_emotionå‡½æ•°
    
    å‚æ•°:
        message (str): ç”¨äºæƒ…æ„Ÿåˆ†æçš„æ¶ˆæ¯æ–‡æœ¬
        client (OpenAI): OpenAIå®¢æˆ·ç«¯å®ä¾‹ï¼Œå¯é€‰
        
    è¿”å›:
        str: é¢„æµ‹çš„æƒ…æ„Ÿç±»å‹
    """
    return await predict_emotion(message, client)

# å®šä¹‰echoå‡½æ•°ï¼Œå¤„ç†éŸ³é¢‘è¾“å…¥å¹¶è¿”å›éŸ³é¢‘è¾“å‡º
def echo(audio: tuple[int, np.ndarray], message: str, input_data: InputData, next_action = "", video_frames = None):
    # è·å–ç”¨æˆ·ä¼šè¯çŠ¶æ€
    session = get_user_session(input_data.webrtc_id)
    whisper_config = get_user_whisper_config(input_data.webrtc_id)
    logging.info(f"æ‘„åƒå¤´çŠ¶æ€: {input_data.is_camera_on}")
    
    # è®°å½•è§†é¢‘å¸§ä¿¡æ¯
    if video_frames and input_data.is_camera_on:
        num_frames = len(video_frames) if video_frames else 0
        logging.info(f"æ¥æ”¶åˆ° {num_frames} å¸§è§†é¢‘æ•°æ®")
    
    prompt = "[AIä¸»åŠ¨å‘èµ·å¯¹è¯]next Action: " + next_action
    user_id = generate_unique_user_id(session["user_name"])
    if next_action == "":
        stt_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        logging.info(f"ç”¨æˆ· {input_data.webrtc_id} æ­£åœ¨æ‰§è¡ŒSTT")  # è®°å½•æ—¥å¿—
        # ä½¿ç”¨å·¥å…·å‡½æ•°è¿è¡Œå¼‚æ­¥è½¬å½•å‡½æ•°ï¼Œä¼ å…¥é…ç½®
        prompt = run_async(transcribe, audio, whisper_config["api_key"], whisper_config["base_url"], whisper_config["model"])
        # ç”Ÿæˆç”¨æˆ·å”¯ä¸€ID
        if prompt == "":  # å¦‚æœè½¬å½•ç»“æœä¸ºç©º
            logging.info("STTè¿”å›ç©ºå­—ç¬¦ä¸²")  # è®°å½•æ—¥å¿—
            return  # ç»“æŸå‡½æ•°
        logging.info(f"STTå“åº”: {prompt}")  # è®°å½•è½¬å½•ç»“æœ
    mem0_config = get_user_mem0_config(input_data.webrtc_id)
    memory_client = AsyncMemoryClient(api_key=mem0_config["api_key"])
    search_result = run_async(memory_client.search, query=prompt, user_id=user_id, limit=3)
    logging.info(f"æœç´¢ç»“æœ: {search_result}")
    # ç¡®ä¿ä»æœç´¢ç»“æœä¸­æ­£ç¡®è·å–è®°å¿†
    memories_text = "\n".join(memory["memory"] for memory in search_result)
    logging.info(f"è®°å¿†æ–‡æœ¬: {memories_text}")
    final_prompt = f"Relevant Memories/Facts:\n{memories_text}\n\nUser Question: {prompt}"
    if next_action == "":
        # å°†ç”¨æˆ·çš„è¾“å…¥æ·»åŠ åˆ°ç”¨æˆ·æ¶ˆæ¯å†å²
        session["messages"].append({"role": "user", "content": final_prompt})
        # å‘é€ç”¨æˆ·è¯­éŸ³è½¬æ–‡å­—ç»“æœåˆ°å‰ç«¯
        transcript_json = json.dumps({"type": "transcript", "data": f"{prompt}"})
        yield AdditionalOutputs(transcript_json)
        # è®°å½•è¯­éŸ³è¯†åˆ«æ‰€ç”¨æ—¶é—´
        logging.info(f"STTè€—æ—¶ {time.time() - stt_time} ç§’")
    # è®°å½•LLMå¼€å§‹æ—¶é—´
    llm_time = time.time()
    # è·å–ç”¨æˆ·çš„OpenAIå®¢æˆ·ç«¯å’ŒAIæ¨¡å‹
    client = get_user_openai_client(input_data.webrtc_id)
    model = get_user_ai_model(input_data.webrtc_id)
    siliconflow_config = get_user_siliconflow_config(input_data.webrtc_id)
    
    # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨ - ä¸ºOpenAI APIåˆ›å»ºæ·±æ‹·è´ï¼Œé˜²æ­¢ä¿®æ”¹åŸå§‹ä¼šè¯å†å²
    messages_for_api = session["messages"].copy()
    
    # å¦‚æœæœ‰è§†é¢‘å¸§ä¸”æ‘„åƒå¤´å·²å¼€å¯ï¼Œæ·»åŠ è§†é¢‘å¸§åˆ°APIè¯·æ±‚ä¸­
    if video_frames and input_data.is_camera_on and len(video_frames) > 0:
        logging.info(f"æ­£åœ¨å°† {len(video_frames)} å¸§è§†é¢‘æ•°æ®ä¼ é€’ç»™OpenAI API")
        visual_messages = []
        for frame in video_frames:
            visual_messages.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{frame['frame_data']}",
                    "detail": "high"  # æŒ‡å®šé«˜ç»†èŠ‚çº§åˆ«
                }
            })
        if len(messages_for_api) > 0 and messages_for_api[-1]["role"] == "user":
            # å¦‚æœæœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œå°†å…¶å†…å®¹è½¬æ¢ä¸ºæ•°ç»„æ ¼å¼ï¼Œæ·»åŠ è§†é¢‘å¸§
            last_msg = messages_for_api[-1]
            text_content = last_msg["content"]
            last_msg["content"] = [{"type": "text", "text": text_content}] + visual_messages
        else:
            # å¦‚æœæ²¡æœ‰ç”¨æˆ·æ¶ˆæ¯æˆ–æœ€åä¸€æ¡ä¸æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„ç”¨æˆ·æ¶ˆæ¯
            sys_msg_with_frames = {
                "role": "user", 
                "content": [
                    {"type": "text", "text": "ç”¨æˆ·æä¾›äº†ä»¥ä¸‹è§†é¢‘å¸§ç”¨äºåˆ†æï¼Œè¯·æ ¹æ®å›¾åƒå†…å®¹æä¾›é€‚å½“çš„å›å¤ï¼š"},
                    *visual_messages
                ]
            }
            messages_for_api.append(sys_msg_with_frames)
    
    # ä½¿ç”¨å°è£…çš„æµå¤„ç†å‡½æ•°
    full_response = ""
    stream_generator = process_llm_stream(
        client=client,
        messages=messages_for_api,  # ä½¿ç”¨å¯èƒ½åŒ…å«è§†é¢‘å¸§çš„æ¶ˆæ¯å‰¯æœ¬
        model=model,
        siliconflow_config=siliconflow_config,
        voice_output_language=session["voice_output_language"],
        text_output_language=session["text_output_language"],
        is_same_language=session["is_same_language"],
        run_predict_emotion=run_predict_emotion,
        ai_stream=ai_stream,
        text_to_speech_stream=text_to_speech_stream,
        max_context_length=20,
    )
    
    # å¤„ç†ç”Ÿæˆå™¨çš„è¾“å‡º
    for item in stream_generator:
        if isinstance(item, str):
            full_response = item
        else:
            yield item

    # å°†åŠ©æ‰‹çš„å“åº”æ·»åŠ åˆ°ç”¨æˆ·æ¶ˆæ¯å†å²
    conversation_messages = [
        {"role": "user", "content": prompt},
        {"role": "assistant", "content": full_response}
    ]
    session["messages"].append({"role": "assistant", "content": full_response + " "})
    logging.info(f"LLMå“åº”: {full_response}")  # è®°å½•LLMå“åº”
    
    # ä¿å­˜å¯¹è¯è®°å¿†
    memory_client.add(conversation_messages, user_id=user_id)
    logging.info(f"LLMè€—æ—¶ {time.time() - llm_time} ç§’")  # è®°å½•LLMæ‰€ç”¨æ—¶é—´
    
    # LLMå“åº”å®Œæˆåï¼Œè§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨
    try:
        # åˆ›å»ºActionPlannerå®ä¾‹
        action_planner = ActionPlanner(conversation_history=session["messages"][-5:])
        # å¼‚æ­¥æ‰§è¡Œè¡ŒåŠ¨è®¡åˆ’
        next_action = run_async(action_planner.plan_next_action, client)
        # æ›´æ–°ç”¨æˆ·ä¼šè¯ä¸­çš„next_actionå­—æ®µ
        session["next_action"] = next_action
        logging.info(f"ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’: {next_action}")
        
        # é€šçŸ¥å‰ç«¯ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’
        next_action_json = json.dumps({"type": "next_action", "data": next_action})
        yield AdditionalOutputs(next_action_json)
    except Exception as e:
        logging.error(f"è§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨å¤±è´¥: {str(e)}")
        session["next_action"] = "share_memory"  # å¤±è´¥æ—¶é»˜è®¤ä¸ºåˆ†äº«è®°å¿†

# åˆ›å»ºä¸€ä¸ªåŒ…è£…å‡½æ•°æ¥æ¥æ”¶æ¥è‡ªStreamçš„webrtc_idå‚æ•°
def startup_wrapper(*args):
    logging.info(f"startup_wrapper: {args}")
    return start_up(args[1].webrtc_id)

# ä½¿ç”¨echoå‡½æ•°ç›´æ¥ä½œä¸ºå›è°ƒ
reply_handler = ReplyOnPause(echo,
    startup_fn=startup_wrapper,
    can_interrupt=True,
    model=vad_model
    )

# åˆ›å»ºStreamå¯¹è±¡ï¼Œç”¨äºå¤„ç†WebRTCæµ
stream = Stream(reply_handler, 
            modality="audio",  # è®¾ç½®æ¨¡æ€ä¸ºéŸ³é¢‘
            rtc_configuration=rtc_configuration,
            mode="send-receive",  # è®¾ç½®æ¨¡å¼ä¸ºå‘é€å’Œæ¥æ”¶
            time_limit=DEFAULT_TIME_LIMIT,
            concurrency_limit=DEFAULT_CONCURRENCY_LIMIT
        )

# ä½¿ç”¨ lifespan ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ›¿ä»£ on_event
@asynccontextmanager
async def lifespan(app: fastapi.FastAPI):
    # å¯åŠ¨æ—¶æ‰§è¡Œçš„ä»£ç 
    cleanup_task = asyncio.create_task(cleanup_expired_sessions())
    yield
    # å…³é—­æ—¶æ‰§è¡Œçš„ä»£ç 
    cleanup_task.cancel()
    try:
        await cleanup_task
    except asyncio.CancelledError:
        logging.info("æ¸…ç†ä»»åŠ¡å·²å–æ¶ˆ")

# åˆ›å»ºFastAPIåº”ç”¨ï¼Œä½¿ç”¨lifespanå‚æ•°
app = fastapi.FastAPI(lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®æ›´æ–°å¤„ç†å‡½æ•°ï¼ˆç”¨äºå¤„ç†ç”¨æˆ·é…ç½®æ›´æ–°ï¼‰
def handle_config_update(webrtc_id, message, data):
    if message == "config_updated" and isinstance(data, InputData):
        logging.info(f"ç”¨æˆ· {webrtc_id} é…ç½®å·²æ›´æ–°")
        
        # å¦‚æœç”¨æˆ·ä¹‹å‰æœ‰ä¼šè¯ï¼Œåˆ™æ›´æ–°ä¼šè¯ä¿¡æ¯
        if webrtc_id in user_sessions:
            session = user_sessions[webrtc_id]
            
            # æ›´æ–°ç”¨æˆ·ä¼šè¯çš„é…ç½®
            if data.voice_output_language:
                session["voice_output_language"] = data.voice_output_language
            if data.text_output_language:
                session["text_output_language"] = data.text_output_language
            if data.system_prompt:
                session["system_prompt"] = data.system_prompt
            if data.user_name:
                session["user_name"] = data.user_name
                
            # æ›´æ–°æ˜¯å¦ç›¸åŒè¯­è¨€
            session["is_same_language"] = (session["voice_output_language"] == session["text_output_language"])
            
            # é‡æ–°ç”Ÿæˆç³»ç»Ÿæç¤º
            sys_prompt = generate_sys_prompt(
                voice_output_language=session["voice_output_language"],
                text_output_language=session["text_output_language"],
                is_same_language=session["is_same_language"],
                current_user_name=session["user_name"],
                system_prompt=session["system_prompt"],
                model=get_user_ai_model(webrtc_id)
            )
            
            # æ›´æ–°æ¶ˆæ¯åˆ—è¡¨ä¸­çš„ç³»ç»Ÿæç¤º
            if len(session["messages"]) > 0 and session["messages"][0]["role"] == "system":
                session["messages"][0]["content"] = sys_prompt
            else:
                session["messages"].insert(0, {"role": "system", "content": sys_prompt})
        
        # å¦‚æœç”¨æˆ·æœ‰OpenAIå®¢æˆ·ç«¯ï¼Œåˆ™æ ¹æ®æ–°é…ç½®æ›´æ–°å®¢æˆ·ç«¯
        if webrtc_id in openai_clients and (data.llm_api_key or data.llm_base_url):
            api_key = data.llm_api_key if data.llm_api_key else DEFAULT_LLM_API_KEY
            base_url = data.llm_base_url if data.llm_base_url else DEFAULT_LLM_BASE_URL
            
            openai_clients[webrtc_id] = OpenAI(
                api_key=api_key,
                base_url=base_url
            )

# åˆå§‹åŒ–è·¯ç”±å™¨ï¼Œä¼ é€’é…ç½®å¤„ç†å‡½æ•°
init_router(stream, rtc_configuration, handle_config_update)

# æŒ‚è½½WebRTCæµ
stream.mount(app)

# åŒ…å«è·¯ç”±
app.include_router(router)

# æ·»åŠ ä¸»å‡½æ•°ï¼Œå½“è„šæœ¬ç›´æ¥è¿è¡Œæ—¶å¯åŠ¨uvicornæœåŠ¡å™¨
if __name__ == "__main__":
    import uvicorn
    # ä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡ PORTï¼Œå¦‚æœæ²¡æœ‰åˆ™é»˜è®¤ 8080
    port = int(os.getenv("PORT", 8080))
    logging.info(f"å¯åŠ¨æœåŠ¡å™¨ï¼Œç›‘å¬ 0.0.0.0:{port}")
    uvicorn.run(app, host="0.0.0.0", port=port)


#11